{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Make sure you're running the latest Julia! You will need to use an app like \"jill\" to get this on Ubuntu (the system packages are old).\n",
    "\n",
    "To use this notebook, run the following to install the dependencies. Note, the first time you use anything (library, function, etc), Julia compiles it. This means that writing `using CUDA` takes ~1m42s on my workstation the first time I run it. Be warned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg; \n",
    "Pkg.add(\"CUDA\")\n",
    "Pkg.add(\"IntervalOptimisation\")\n",
    "Pkg.add(\"Symbolics\")\n",
    "Pkg.add(\"IntervalArithmetic\")\n",
    "Pkg.add(\"JuMP\")\n",
    "Pkg.add(\"EAGO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First adventures\n",
    "\n",
    "Julia is like python but also like C++. It also has tons of built in math, like numpy-style array operations are in by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       "  6.0\n",
       " 11.0\n",
       " 18.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A generic function\n",
    "f(x) = 2*x + x^2 + 3\n",
    "\n",
    "display(f(2))\n",
    "\n",
    "#Make a vector\n",
    "v = [1.0, 2,3]\n",
    "\n",
    "f.(v)#The dot is special when it appears before an operator (like the call operator here). It generally means do this elementwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Julia determined the type (Float64) from the literal's used (in this case the 1.0). It naturally has mathematical operations defined too, like vector addition. I can even do a dot product   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "dot(v,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't sexy enough. Write `v ` then `\\cdot` and press tab to autocomplete (yes latex is the way these are defined), then put `v` and you get a dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v ⋅ v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, we have unicode, and a lot of it is plumbed into real mathematical definitions. We can even use it in our variable names to give them subscripts by typing `C\\_2⭾`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "π = 3.1415926535897..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C₂ = 1\n",
    "π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants like pi are already there, but even these have been improved. What exactly is that pi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrational{:π}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It understands Irrationals! This means its an arbitrary precision element too as it retains its symbolic nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.283185307179586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(2π)\n",
    "typeof(2π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it often falls back to float64 (double) by default, which is what we want MOST of the time for speed. But we can of course request arbitrary precision if we want... Here's a float256 (by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.283185307179586476925286766559005768394338798750211641949889184615632812572396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BigFloat(2)*π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough digits yet? Lets look at functions again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f(x) = 2 + 5sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is f?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Core.CodeInfo}:\n",
       " CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = Main.cos(0.5)\n",
       "\u001b[90m└──\u001b[39m      return %1\n",
       ")\n",
       " CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = Main.sin(x)\n",
       "\u001b[90m│  \u001b[39m %2 = 5 * %1\n",
       "\u001b[90m│  \u001b[39m %3 = 2 + %2\n",
       "\u001b[90m└──\u001b[39m      return %3\n",
       ")\n",
       " CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = Core.apply_type(Base.Val, 2)\n",
       "\u001b[90m│  \u001b[39m %2 = (%1)()\n",
       "\u001b[90m│  \u001b[39m %3 = Base.literal_pow(Main.:^, x, %2)\n",
       "\u001b[90m│  \u001b[39m %4 = Core.apply_type(Base.Val, 2)\n",
       "\u001b[90m│  \u001b[39m %5 = (%4)()\n",
       "\u001b[90m│  \u001b[39m %6 = Base.literal_pow(Main.:^, y, %5)\n",
       "\u001b[90m│  \u001b[39m %7 = %3 + %6\n",
       "\u001b[90m└──\u001b[39m      return %7\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_lowered(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! I can see the code! Hmm, looks a little generic and slow. What if I put the type information in, do I see more code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = invoke Main.sin(x::Float64)\u001b[36m::Float64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %2 = Base.mul_float(5.0, %1)\u001b[36m::Float64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %3 = Base.add_float(2.0, %2)\u001b[36m::Float64\u001b[39m\n",
       "\u001b[90m└──\u001b[39m      return %3\n",
       ") => Float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@code_typed f(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its compiling to some specialised operations for floats where its tracking the types, the values, and the arguments. Can we keep going till we hit bare metal (assembly)? We can with @code_native, but @code_llvm is a more human-readable representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m;  @ /home/mjki2mb2/testJulia/test.ipynb:1 within `f`\u001b[39m\n",
      "\u001b[95mdefine\u001b[39m \u001b[36mdouble\u001b[39m \u001b[93m@julia_f_3234\u001b[39m\u001b[33m(\u001b[39m\u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[33m)\u001b[39m \u001b[0m#0 \u001b[33m{\u001b[39m\n",
      "\u001b[91mtop:\u001b[39m\n",
      "  \u001b[0m%1 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m= \u001b[96m\u001b[1mcall\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[93m@j_sin_3236\u001b[39m\u001b[33m(\u001b[39m\u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[33m)\u001b[39m \u001b[0m#0\n",
      "\u001b[90m; ┌ @ promotion.jl:389 within `*` @ float.jl:385\u001b[39m\n",
      "   \u001b[0m%2 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%1\u001b[0m, \u001b[33m5.000000e+00\u001b[39m\n",
      "\u001b[90m; └\u001b[39m\n",
      "\u001b[90m; ┌ @ promotion.jl:388 within `+` @ float.jl:383\u001b[39m\n",
      "   \u001b[0m%3 \u001b[0m= \u001b[96m\u001b[1mfadd\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%2\u001b[0m, \u001b[33m2.000000e+00\u001b[39m\n",
      "\u001b[90m; └\u001b[39m\n",
      "  \u001b[96m\u001b[1mret\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%3\n",
      "\u001b[33m}\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "code_llvm(f, (Float64,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, llvm's Intermediate Representation, the last stage before assembly! All created whenever we use the function, but not before! So we always get compiled, fully optimised code.\n",
    "\n",
    "So far, this is just C++ with python syntax. What makes Julia special? Lets take a look at the source code of `cos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "cos(x::<b>T</b>)<i> where T<:Union{Float32, Float64}</i> in Base.Math at <a href=\"https://github.com/JuliaLang/julia/tree/0434deb161e17103eabdd7d82b17a1cd6b410572/base/special/trig.jl#L98\" target=\"_blank\">special/trig.jl:98</a>"
      ],
      "text/plain": [
       "cos(x::T) where T<:Union{Float32, Float64} in Base.Math at special/trig.jl:98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@which cos(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even edit the source code on your computer using @edit, or scroll it using @less.\n",
    "\n",
    "What you should see is some Horners' method implementations. But Julia is aware of this code right now, while compiling your code. It can optimise. Lets check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m     return 0.8775825618903728\n",
       ") => Float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g() = cos(0.5)\n",
    "\n",
    "@code_typed g()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this might seem to be an obvious optimisation to you now, its not obvious for interpreted languages like python. Also, this is happening for ALL your code. Basically anything that doesn't change, is evaluated for free. Julia, thanks to LLVM, can deeply inspect your code and optimise static branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA\n",
    "We're always writing fairly abstract functions that then get adapted to native code only when run when types are known. Changing the type can change more than just the instructions, it can change where all the code runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element CuArray{Float64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 13.158529015192103\n",
       " 17.09070257317432\n",
       " 23.85887999194013\n",
       " 32.75680249530793\n",
       " 42.95892427466314\n",
       " 54.27941549819893\n",
       " 67.34301340128121\n",
       " 83.01064175337662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using CUDA\n",
    "gpu_v = CuArray([1,2,3,4,5,6,7,8]) #This array now lives on the GPU\n",
    "\n",
    "#Some generic function\n",
    "f₂(x) = x + 12 + x^2 - sin(x)\n",
    "\n",
    "f₂.(gpu_v) # This is run on the GPU!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I gotta see what this looks like in GPU assembly (warning, its filled with inlined code from the library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\u001b[0m.text\n",
      "\t\u001b[0m.file\t\u001b[0m\"f\\342\\202\\202\"\n",
      "\t\u001b[0m.globl\t\u001b[0m\"julia_f₂_13080\"                \u001b[90m# -- Begin function julia_f₂_13080\u001b[39m\n",
      "\t\u001b[0m.p2align\t\u001b[33m4\u001b[39m\u001b[0m, \u001b[33m0x90\u001b[39m\n",
      "\t\u001b[0m.type\t\u001b[0m\"julia_f₂_13080\"\u001b[0m,\u001b[0m@function\n",
      "\u001b[91m\"julia_f₂_13080\":\u001b[39m                       \u001b[90m# @\"julia_f\\E2\\82\\82_13080\"\u001b[39m\n",
      "\u001b[90m; ┌ @ /home/mjki2mb2/testJulia/test.ipynb:5 within `f₂`\u001b[39m\n",
      "\t\u001b[0m.cfi_startproc\n",
      "\u001b[90m# %bb.0:                                # %top\u001b[39m\n",
      "\t\u001b[96m\u001b[1msubq\u001b[22m\u001b[39m\t\u001b[33m$24\u001b[39m\u001b[0m, \u001b[0m%rsp\n",
      "\t\u001b[0m.cfi_def_cfa_offset \u001b[33m32\u001b[39m\n",
      "\u001b[90m; │┌ @ intfuncs.jl:340 within `literal_pow`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mmovq\u001b[22m\u001b[39m\t\u001b[0m%rdi\u001b[0m, \u001b[33m8\u001b[39m\u001b[33m(\u001b[39m\u001b[0m%rsp\u001b[33m)\u001b[39m\n",
      "\t\u001b[96m\u001b[1mmovabsq\u001b[22m\u001b[39m\t\u001b[33m$140016101937312\u001b[39m\u001b[0m, \u001b[0m%rax          \u001b[90m# imm = 0x7F580A04D0A0\u001b[39m\n",
      "\t\u001b[96m\u001b[1mmovq\u001b[22m\u001b[39m\t\u001b[0m%rax\u001b[0m, \u001b[33m16\u001b[39m\u001b[33m(\u001b[39m\u001b[0m%rsp\u001b[33m)\u001b[39m\n",
      "\t\u001b[96m\u001b[1mmovabsq\u001b[22m\u001b[39m\t\u001b[93m$ijl_apply_generic\u001b[39m\u001b[0m, \u001b[0m%rax\n",
      "\t\u001b[96m\u001b[1mmovabsq\u001b[22m\u001b[39m\t\u001b[33m$140015892575680\u001b[39m\u001b[0m, \u001b[0m%rdi          \u001b[90m# imm = 0x7F57FD8A35C0\u001b[39m\n",
      "\t\u001b[96m\u001b[1mleaq\u001b[22m\u001b[39m\t\u001b[33m8\u001b[39m\u001b[33m(\u001b[39m\u001b[0m%rsp\u001b[33m)\u001b[39m\u001b[0m, \u001b[0m%rsi\n",
      "\t\u001b[96m\u001b[1mmovl\u001b[22m\u001b[39m\t\u001b[33m$2\u001b[39m\u001b[0m, \u001b[0m%edx\n",
      "\t\u001b[96m\u001b[1mcallq\u001b[22m\u001b[39m\t\u001b[0m*\u001b[0m%rax\n",
      "\t\u001b[96m\u001b[1mud2\u001b[22m\u001b[39m\n",
      "\u001b[91m.Lfunc_end0:\u001b[39m\n",
      "\t\u001b[0m.size\t\u001b[0m\"julia_f₂_13080\"\u001b[0m, \u001b[0m.Lfunc_end0-\"julia_f₂_13080\"\n",
      "\t\u001b[0m.cfi_endproc\n",
      "\u001b[90m; └└\u001b[39m\n",
      "                                        \u001b[90m# -- End function\u001b[39m\n",
      "\t\u001b[0m.section\t\u001b[0m\".note.GNU-stack\"\u001b[0m,\u001b[0m\"\"\u001b[0m,\u001b[0m@progbits\n",
      "nothing"
     ]
    }
   ],
   "source": [
    "using InteractiveUtils #We use the macro @code_native from here as its a bit easier to specify the function specialisation by a variable/call\n",
    "show(@code_native f₂(gpu_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f₃ (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "x^{2} + y^{2}\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "x^2 + y^2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Symbolics\n",
    "\n",
    "#Here's a normal function\n",
    "f₃(a, b) = a^2+b^2\n",
    "display(f₃)\n",
    "\n",
    "#I can use symbolic types to trace the function\n",
    "@variables x, y, t\n",
    "display(f(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about discovering the governing differential equations behind data https://github.com/SciML/DataDrivenDiffEq.jl?\n",
    "Global non-linear constrained optimisation (for small enough dimensionality) https://github.com/PSORLab/EAGO.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimisation\n",
    "\n",
    "Want global minimisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.102457, -0.101645], Interval{Float64}[[3.48339, 3.4844], [3.47441, 3.47495], [3.47231, 3.47284], [3.47335, 3.47389], [3.47388, 3.47442], [3.47023, 3.47077], [3.47127, 3.4718], [3.47546, 3.47599], [3.4765, 3.47703], [3.46971, 3.47024]  …  [3.49105, 3.49159], [3.45469, 3.45522], [3.45419, 3.4547], [3.45367, 3.4542], [3.49158, 3.49209], [3.49208, 3.4926], [3.45316, 3.45368], [3.49259, 3.49311], [3.45265, 3.45317], [3.4931, 3.49363]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using IntervalArithmetic, IntervalOptimisation\n",
    "const ∞ = Inf\n",
    "minimise(x->sin(x)+(x-3)^2, -∞..∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/testJulia/EAGO`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/testJulia/EAGO/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/testJulia/EAGO/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/testJulia/EAGO/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/testJulia/EAGO/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# EAGO needs some older code, so we can install it in its own environment, called \"EAGO\", to prevent the package manager downgrading some core functionality\n",
    "using Pkg\n",
    "Pkg.activate(\"EAGO\") #Activate the EAGO environment\n",
    "Pkg.add(\"JuMP\")\n",
    "Pkg.add(\"EAGO\") # Install EAGO inside this environment\n",
    "\n",
    "Pkg.activate() #Go back to the default environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP._Derivatives\n",
    "using JuMP, EAGO\n",
    "\n",
    "m = Model(EAGO.Optimizer)\n",
    "\n",
    "# Define bounded variables\n",
    "xL = [10.0; 0.0; 0.0; 0.0; 0.0; 85.0; 90.0; 3.0; 1.2; 145.0]\n",
    "xU = [2000.0; 16000.0; 120.0; 5000.0; 2000.0; 93.0; 95.0; 12.0; 4.0; 162.0]\n",
    "@variable(m, xL[i] <= x[i=1:10] <= xU[i])\n",
    "\n",
    "# Define nonlinear constraints\n",
    "@NLconstraint(m, e1, -x[1]*(1.12+0.13167*x[8]-0.00667* (x[8])^2)+x[4] == 0.0)\n",
    "@NLconstraint(m, e3, -0.001*x[4]*x[9]*x[6]/(98-x[6])+x[3] == 0.0)\n",
    "@NLconstraint(m, e4, -(1.098*x[8]-0.038* (x[8])^2)-0.325*x[6]+x[7] == 57.425)\n",
    "@NLconstraint(m, e5, -(x[2]+x[5])/x[1]+x[8] == 0.0)\n",
    "\n",
    "# Define linear constraints\n",
    "@constraint(m, e2, -x[1]+1.22*x[4]-x[5] == 0.0)\n",
    "@constraint(m, e6, x[9]+0.222*x[10] == 35.82)\n",
    "@constraint(m, e7, -3*x[7]+x[10] == -133.0)\n",
    "\n",
    "# Define nonlinear objective\n",
    "@NLobjective(m, Max, 0.063*x[4]*x[7] - 5.04*x[1] - 0.035*x[2] - 10*x[3] - 3.36*x[5])\n",
    "\n",
    "# Solve the optimization problem\n",
    "JuMP.optimize!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/.julia/environments/v1.8`\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
